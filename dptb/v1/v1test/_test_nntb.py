import logging

from dptb.nnet.nntb import NNTB
import torch as th
import numpy as np
import copy

batch_env = {'N-N': th.tensor([[ 0.0000,  0.0000,  7.0000, 0.0000,  7.0000,  0,0,0,0.3994, -1.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  7.0000, 0.0000,  7.0000,0,0,0,  0.3994, -1.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  7.0000, 0.0000,  7.0000,0,0,0,  0.3994,  1.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  7.0000, 0.0000,  7.0000,0,0,0,  0.3994, -0.5000,  0.8660,  0.0000],
         [ 0.0000,  0.0000,  7.0000, 0.0000,  7.0000,0,0,0,  0.3994,  0.5000,  0.8660,  0.0000],
         [ 0.0000,  0.0000,  7.0000, 0.0000,  7.0000,0,0,0,  0.3994, -0.5000, -0.8660,  0.0000],
         [ 0.0000,  0.0000,  7.0000, 0.0000,  7.0000,0,0,0,  0.3994,  0.5000, -0.8660,  0.0000]]),
 'N-B': th.tensor([[ 0.0000e+00,  0.0000e+00,  7.0000e+00,  1.0000,  5.0000,0,0,0, 6.9171e-01, -8.6603e-01,
          -5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  7.0000e+00, 1.0000,  5.0000,0,0,0,  6.9171e-01, -8.6603e-01,
          -5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  7.0000e+00, 1.0000,  5.0000,0,0,0,  3.3152e-01, -8.6603e-01,
           5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  7.0000e+00, 1.0000,  5.0000,0,0,0,  6.9171e-01, -5.0253e-08,
           1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  7.0000e+00, 1.0000,  5.0000,0,0,0,   3.3152e-01,  8.6603e-01,
           5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  7.0000e+00, 1.0000,  5.0000,0,0,0,  6.9171e-01,  8.6603e-01,
          -5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  7.0000e+00, 1.0000,  5.0000,0,0,0,  3.3152e-01, -2.5092e-08,
          -1.0000e+00,  0.0000e+00]]),
 'B-B': th.tensor([[ 0.0000,  1.0000,  5.0000, 1.0000,  5.0000,0,0,0,  0.3994,  0.5000,  0.8660,  0.0000],
         [ 0.0000,  1.0000,  5.0000, 1.0000,  5.0000,  0.3994,0,0,0,  0.5000,  0.8660,  0.0000],
         [ 0.0000,  1.0000,  5.0000, 1.0000,  5.0000,  0.3994,0,0,0,  0.5000, -0.8660,  0.0000],
         [ 0.0000,  1.0000,  5.0000, 1.0000,  5.0000,  0.3994,0,0,0, -0.5000, -0.8660,  0.0000],
         [ 0.0000,  1.0000,  5.0000, 1.0000,  5.0000,  0.3994, 0,0,0,-1.0000,  0.0000,  0.0000],
         [ 0.0000,  1.0000,  5.0000, 1.0000,  5.0000,  0.3994,0,0,0,  1.0000,  0.0000,  0.0000],
         [ 0.0000,  1.0000,  5.0000, 1.0000,  5.0000,  0.3994,0,0,0, -0.5000,  0.8660,  0.0000]]),
 'B-N': th.tensor([[ 0.0000e+00,  1.0000e+00,  5.0000e+00, 0.0000,  7.0000, 0,0,0, 3.3152e-01,  2.5092e-08,
           1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  1.0000e+00,  5.0000e+00, 0.0000,  7.0000, 0,0,0, 3.3152e-01,  2.5092e-08,
           1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  1.0000e+00,  5.0000e+00, 0.0000,  7.0000, 0,0,0, 3.3152e-01,  8.6603e-01,
          -5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  1.0000e+00,  5.0000e+00, 0.0000,  7.0000, 0,0,0, 6.9171e-01,  5.0253e-08,
          -1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  1.0000e+00,  5.0000e+00, 0.0000,  7.0000, 0,0,0, 3.3152e-01, -8.6603e-01,
          -5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  1.0000e+00,  5.0000e+00, 0.0000,  7.0000, 0,0,0, 6.9171e-01, -8.6603e-01,
           5.0000e-01,  0.0000e+00],
         [ 0.0000e+00,  1.0000e+00,  5.0000e+00, 0.0000,  7.0000, 0,0,0, 6.9171e-01,  8.6603e-01,
           5.0000e-01,  0.0000e+00]])}

batch_bond={"0":th.tensor([[ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
         -2.0000e+00,  0.0000e+00,  0.0000e+00,  3.8249e+00, -9.8198e-01,
         -1.8898e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  7.0000e+00,  0.0000e+00,
         -1.0000e+00,  0.0000e+00,  0.0000e+00,  2.5040e+00, -1.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.4457e+00, -8.6603e-01,
         -5.0000e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
          1.0000e+00,  0.0000e+00,  0.0000e+00,  3.8249e+00,  9.8198e-01,
         -1.8898e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
         -1.0000e+00,  1.0000e+00,  0.0000e+00,  2.8914e+00, -8.6603e-01,
          5.0000e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  7.0000e+00,  0.0000e+00,
          0.0000e+00,  1.0000e+00,  0.0000e+00,  2.5040e+00, -5.0000e-01,
          8.6603e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.4457e+00, -5.0253e-08,
          1.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  7.0000e+00,  0.0000e+00,
          1.0000e+00,  1.0000e+00,  0.0000e+00,  2.5040e+00,  5.0000e-01,
          8.6603e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
          1.0000e+00,  1.0000e+00,  0.0000e+00,  2.8914e+00,  8.6603e-01,
          5.0000e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
          0.0000e+00,  2.0000e+00,  0.0000e+00,  3.8249e+00, -3.2733e-01,
          9.4491e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
          1.0000e+00,  2.0000e+00,  0.0000e+00,  3.8249e+00,  3.2733e-01,
          9.4491e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4457e+00,  8.6603e-01,
         -5.0000e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
         -1.0000e+00, -1.0000e+00,  0.0000e+00,  2.8914e+00, -2.5092e-08,
         -1.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
         -2.0000e+00, -1.0000e+00,  0.0000e+00,  3.8249e+00, -6.5465e-01,
         -7.5593e-01,  0.0000e+00],
        [ 0.0000e+00,  7.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,
          0.0000e+00, -1.0000e+00,  0.0000e+00,  3.8249e+00,  6.5465e-01,
         -7.5593e-01,  0.0000e+00],
        [ 0.0000e+00,  5.0000e+00,  1.0000e+00,  5.0000e+00,  1.0000e+00,
          1.0000e+00,  1.0000e+00,  0.0000e+00,  2.5040e+00,  5.0000e-01,
          8.6603e-01,  0.0000e+00],
        [ 0.0000e+00,  5.0000e+00,  1.0000e+00,  5.0000e+00,  1.0000e+00,
          0.0000e+00, -1.0000e+00,  0.0000e+00,  2.5040e+00,  5.0000e-01,
         -8.6603e-01,  0.0000e+00],
        [ 0.0000e+00,  5.0000e+00,  1.0000e+00,  5.0000e+00,  1.0000e+00,
         -1.0000e+00,  0.0000e+00,  0.0000e+00,  2.5040e+00, -1.0000e+00,
          0.0000e+00,  0.0000e+00]])}


batch_bond_hops=np.array([[0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00, -2.00000000e+00,  0.00000000e+00, 0.00000000e+00,  3.82492328e+00, -9.81980503e-01, -1.88982248e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00, -1.00000000e+00,  0.00000000e+00, 0.00000000e+00,  1.44568515e+00, -8.66025388e-01, -5.00000000e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00,  1.00000000e+00,  0.00000000e+00, 0.00000000e+00,  3.82492304e+00,  9.81980503e-01, -1.88982263e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00, -1.00000000e+00,  1.00000000e+00, 0.00000000e+00,  2.89137006e+00, -8.66025448e-01, 4.99999970e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00,  0.00000000e+00,  1.00000000e+00, 0.00000000e+00,  1.44568491e+00, -5.02525346e-08, 1.00000000e+00,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, 0.00000000e+00,  2.89137006e+00,  8.66025388e-01, 5.00000000e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00,  0.00000000e+00,  2.00000000e+00, 0.00000000e+00,  3.82492304e+00, -3.27326864e-01, 9.44911182e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00,  1.00000000e+00,  2.00000000e+00, 0.00000000e+00,  3.82492304e+00,  3.27326834e-01, 9.44911182e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00,  0.00000000e+00,  0.00000000e+00, 0.00000000e+00,  1.44568503e+00,  8.66025388e-01, -5.00000060e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00, -1.00000000e+00, -1.00000000e+00, 0.00000000e+00,  2.89137006e+00, -2.50916781e-08, -1.00000000e+00,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00, -2.00000000e+00, -1.00000000e+00, 0.00000000e+00,  3.82492328e+00, -6.54653668e-01, -7.55928934e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  5.00000000e+00, 1.00000000e+00,  0.00000000e+00, -1.00000000e+00, 0.00000000e+00,  3.82492304e+00,  6.54653668e-01, -7.55928993e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  7.00000000e+00, 0.00000000e+00, -1.00000000e+00,  0.00000000e+00, 0.00000000e+00,  2.50399995e+00, -1.00000000e+00, 0.00000000e+00,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  7.00000000e+00, 0.00000000e+00,  0.00000000e+00,  1.00000000e+00, 0.00000000e+00,  2.50399995e+00, -5.00000000e-01, 8.66025388e-01,  0.00000000e+00],
       [0, 7.00000000e+00,  0.00000000e+00,  7.00000000e+00, 0.00000000e+00,  1.00000000e+00,  1.00000000e+00, 0.00000000e+00,  2.50399995e+00,  5.00000000e-01, 8.66025388e-01,  0.00000000e+00],
       [0, 5.00000000e+00,  1.00000000e+00,  5.00000000e+00, 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, 0.00000000e+00,  2.50399995e+00,  5.00000000e-01, 8.66025388e-01,  0.00000000e+00],
       [0, 5.00000000e+00,  1.00000000e+00,  5.00000000e+00, 1.00000000e+00,  0.00000000e+00, -1.00000000e+00, 0.00000000e+00,  2.50399995e+00,  5.00000000e-01, -8.66025388e-01,  0.00000000e+00],
       [0, 5.00000000e+00,  1.00000000e+00,  5.00000000e+00, 1.00000000e+00, -1.00000000e+00,  0.00000000e+00, 0.00000000e+00,  2.50399995e+00, -1.00000000e+00, 0.00000000e+00,  0.00000000e+00]])

for i in batch_env:
  batch_env[i][:,[1,2,3,4]] = batch_env[i][:,[2,1,4,3]]
batch_env2 = copy.deepcopy(batch_env)
batch_env3 = copy.deepcopy(batch_env)


class Test_NNTB:
    proj_atom_type= ['N', 'B']
    atom_type= ['N', 'B']
    axis_neuron = 10
    env_net_config= [{'n_in': 1, 'n_hidden': 4, 'n_out': 8}, {'n_in': 8, 'n_out': 16}]
    onsite_net_config= {'N': [{'n_in': 160, 'n_hidden': 10, 'n_out': 20}, {'n_in': 20, 'n_hidden': 40, 'n_out': 2}],
                        'B': [{'n_in': 160, 'n_hidden': 10, 'n_out': 20}, {'n_in': 20, 'n_hidden': 40, 'n_out': 2}]}
    bond_net_config={'N-N': [{'n_in': 161, 'n_hidden': 10, 'n_out': 20}, {'n_in': 20, 'n_hidden': 40, 'n_out': 4}],
                     'N-B': [{'n_in': 161, 'n_hidden': 10, 'n_out': 20}, {'n_in': 20, 'n_hidden': 40, 'n_out': 5}],
                     'B-B': [{'n_in': 161, 'n_hidden': 10, 'n_out': 20}, {'n_in': 20, 'n_hidden': 40, 'n_out': 4}]}
    # initialize model options
    nntb = NNTB(
                atomtype = atom_type,
                proj_atomtype = proj_atom_type,
                axis_neuron = axis_neuron,
                onsite_net_config =onsite_net_config,
                env_net_config =env_net_config,
                hopping_net_config = bond_net_config,
                onsite_net_activation = 'tanh',
                env_net_activation='tanh',
                hopping_net_activation='tanh',
                onsite_net_type='ffn',
                env_net_type='res',
                hopping_net_type='ffn',
                if_batch_normalized=False,
                device='cpu',
                dtype=th.float32)

    
    def test_get_desciptor(self):
        batched_dcp = self.nntb.get_desciptor(batch_env)


        assert len(batched_dcp.keys()) == 2
        assert list(batched_dcp.keys()) == ['0-0', '0-1']
        assert batched_dcp['0-0'].shape[0] == 163 
        assert batched_dcp['0-1'].shape[0] == 163
        assert (batched_dcp['0-0'][0:3].detach().numpy().astype(int) == np.array([0, 7, 0])).all()
        assert (batched_dcp['0-1'][0:3].detach().numpy().astype(int) == np.array([0, 5, 1])).all()

    def test_hoppings(self):
        
        batched_dcp = self.nntb.get_desciptor(batch_env2)
        batch_bond_hoppings, batch_hoppings = self.nntb.hopping(batched_dcp=batched_dcp, batch_bond=batch_bond)

        assert np.asarray(batch_bond_hoppings[0]).shape == (18,12)
        assert np.sum(np.asarray(batch_bond_hoppings[0])[:,1:8].astype(int)-batch_bond_hops[:,1:8].astype(int)) < 1e-6
        assert (np.fabs(np.asarray(batch_bond_hoppings[0])[:,8:12].astype(float) - batch_bond_hops[:,8:12].astype(float)) < 1e-4).all()
        assert list(batch_hoppings.keys()) == [0]
        assert len(batch_hoppings[0]) == 18

    def test_onsite(self):
        batched_dcp = self.nntb.get_desciptor(batch_env3)
        batch_bond_onsites, batch_onsiteEs, _ = self.nntb.onsite(batched_dcp=batched_dcp)

        assert np.sum(np.array(batch_bond_onsites[0][:,1:12])-np.array([[7, 0, 7,0, 0,0,0,0, 0, 0, 0], [5,0, 5,1, 1, 0,0,0,0, 0, 0]])) < 1e-6

        assert list(batch_onsiteEs.keys()) == [0]

        assert len(batch_onsiteEs[0]) == 2
        assert batch_onsiteEs[0][0].shape[0] ==2
        assert batch_onsiteEs[0][1].shape[0] ==2